# interactively-refine.folk --
#
#     Implements table-oriented projector-camera end-to-end
#     calibration step.
#

When the pose library is /poseLib/ {

set cc [C]
$cc extend $poseLib

$cc cflags -I./vendor/apriltag
$cc endcflags ./vendor/apriltag/build/libapriltag.so

$cc include <apriltag_pose.h>
$cc include <common/homography.h>
$cc include <common/matd.h>

# Used to generate the initial guess in estimateBoardPose. Kind of
# misuses the AprilTag pose estimation code to do an entire-board
# estimate (which includes multiple tags).
$cc proc baseEstimateBoardPose {Intrinsics cameraIntrinsics
                                double cameraWidth double cameraHeight
                                double[][2] modelTagCorners double[][2] detectedTagCorners
                                int cornersCount} TagPose {
    // We'll fill this in with a .H that represents all the corners.
    apriltag_detection_t det;

    // The normal tag .H homography goes from (+/-1, +/-1) to the
    // camera-detected tag corners.  We will instead create a
    // board-wide homography from board meters position to the
    // camera-detected tag corners.
    float correspondences[cornersCount][4];
    for (int i = 0; i < cornersCount; i++) {
        correspondences[i][0] = modelTagCorners[i][0];
        correspondences[i][1] = modelTagCorners[i][1];

        double undistortedDetectedTagCorners[2];
        rescaleAndUndistort(cameraIntrinsics, cameraWidth, cameraHeight,
                            detectedTagCorners[i],
                            undistortedDetectedTagCorners);
        correspondences[i][2] = undistortedDetectedTagCorners[0];
        correspondences[i][3] = undistortedDetectedTagCorners[1];
    }
    zarray_t correspondencesArr = {
        .el_sz = sizeof(float[4]), .size = cornersCount, .alloc = cornersCount,
        .data = (char*) correspondences
    };
    det.H = homography_compute(&correspondencesArr,
                               HOMOGRAPHY_COMPUTE_FLAG_SVD);
    apriltag_detection_info_t info = {
        .det = &det,
        .tagsize = 2.0, // scale factor = 1.0
        .fx = cameraIntrinsics.fx, .fy = cameraIntrinsics.fy,
        .cx = cameraIntrinsics.cx, .cy = cameraIntrinsics.cy
    };
    apriltag_pose_t pose;
    estimate_pose_for_tag_homography(&info, &pose);

    matd_destroy(det.H);

    TagPose ret;
    memcpy(ret.R, pose.R->data, sizeof(ret.R));
    memcpy(ret.t, pose.t->data, sizeof(ret.t));

    matd_destroy(pose.R);
    matd_destroy(pose.t);
    return ret;
}
$cc proc estimateBoardPose {Intrinsics cameraIntrinsics
                            double cameraWidth double cameraHeight
                            double[][2] modelTagCorners double[][2] detectedTagCorners
                            int cornersCount} TagPose {
    TagPose baseBoardPose =
        baseEstimateBoardPose(cameraIntrinsics, cameraWidth, cameraHeight,
                              modelTagCorners, detectedTagCorners, cornersCount);

    double wX[cornersCount][3];
    double x[cornersCount][2];
    for (int i = 0; i < cornersCount; i++) {
        rescaleAndUndistort(cameraIntrinsics, cameraWidth, cameraHeight,
                            detectedTagCorners[i],
                            x[i]);
        // Apply intrinsics to go from pixel coordinates to normalized
        // image-plane coordinates:
        x[i][0] = (x[i][0] - cameraIntrinsics.cx) / cameraIntrinsics.fx;
        x[i][1] = (x[i][1] - cameraIntrinsics.cy) / cameraIntrinsics.fy;

        wX[i][0] = modelTagCorners[i][0];
        wX[i][1] = modelTagCorners[i][1];
        wX[i][2] = 0;
    }

    matd_t* cRw = matd_create_data(3, 3, (double*) baseBoardPose.R);
    matd_t* ctw = matd_create_data(3, 1, (double*) baseBoardPose.t);

    poseGaussNewton(wX, x, cornersCount, &cRw, &ctw);

    TagPose ret;
    memcpy(ret.R, cRw->data, sizeof(ret.R));
    memcpy(ret.t, ctw->data, sizeof(ret.t));

    matd_destroy(cRw);
    matd_destroy(ctw);
    return ret;
}
set boardLib [$cc compile]

When the AprilTag detector maker is /makeAprilTagDetector/ &\
     the calibration model library is /modelLib/ &\
     the printed calibration tag size is /printedSideLengthMm/ mm &\
     camera /camera/ has intrinsics /cameraIntrinsics/ &\
     camera /camera/ has width /cameraWidth/ height /cameraHeight/ &\
     display /display/ has intrinsics /displayIntrinsics/ &\
     display /display/ has width /displayWidth/ height /displayHeight/ &\
     the calibration is /calibration/ &\
     /someone/ wishes to do interactive refinement {

    fn makeAprilTagDetector
    set tagDetector [makeAprilTagDetector "tagStandard52h13" 2.0 3]

    package require linalg
    namespace import ::math::linearalgebra::scale \
        ::math::linearalgebra::sub ::math::linearalgebra::add

    set printedSideLengthM [/ $printedSideLengthMm 1000.0]
    set model [$modelLib scaleModel [$modelLib unitModel] \
                   $printedSideLengthM]

    fn innerToOuter {center corner} {
        package require linalg
        namespace import ::math::linearalgebra::scale \
            ::math::linearalgebra::sub ::math::linearalgebra::add

        set r [sub $corner $center]
        return [add $center [scale [expr {sqrt(50)/sqrt(18)}] $r]]
    }

    When -serially camera $camera has frame /frame/ at timestamp /frameTimestamp/ {
        set aprilTime [time {
            set tags [$tagDetector detect $frame]
        }]

        package require linalg
        namespace import ::math::linearalgebra::matmul

        set modelPrintedTagCorners [list]
        set detectedPrintedTagCorners [list]
        foreach tag $tags {
            set id [dict get $tag id]
            if {![$modelLib isPrintedTag $id]} { continue }

            lappend modelPrintedTagCorners {*}[dict get $model $id p]
            lappend detectedPrintedTagCorners {*}[dict get $tag p]
        }
        if {[llength $detectedPrintedTagCorners] < 4} { return }

        # Do a single board-wide pose estimate.
        set pose [$boardLib estimateBoardPose $cameraIntrinsics \
                      $cameraWidth $cameraHeight \
                      $modelPrintedTagCorners $detectedPrintedTagCorners \
                      [llength $detectedPrintedTagCorners]]
        set R_boardToCamera [dict get $pose R]
        set t_boardToCamera [dict get $pose t]

        set R_cameraToDisplay [dict get $calibration R_cameraToProjector]
        set t_cameraToDisplay [dict get $calibration t_cameraToProjector]

        # Project a bunch of tags based on the pose estimate.
        dict for {id modelTag} $model {
            if {[$modelLib isPrintedTag $id]} { continue }

            set modelInnerCorners [lreverse [dict get $modelTag p]]
            set modelCenter [dict get $modelTag c]
            set modelOuterCorners [lmap modelInnerCorner $modelInnerCorners {
                innerToOuter $modelCenter $modelInnerCorner
            }]

            set projectorOuterCorners [lmap modelOuterCorner $modelOuterCorners {
                set v [list {*}$modelOuterCorner 0]
                set cameraOuterCorner [add [matmul $R_boardToCamera $v] \
                                           $t_boardToCamera]
                set projectorOuterCorner [add [matmul $R_cameraToDisplay $cameraOuterCorner] \
                                              $t_cameraToDisplay]
                $poseLib project $displayIntrinsics \
                    $displayWidth $displayHeight $projectorOuterCorner
            }]

            Hold! -key $id Wish to draw an AprilTag onto $display with \
                id $id corners $projectorOuterCorners background [list 1 1 1 1] \
                layer 100
        }
        # White backdrop to hopefully make the projected tags pop out more:
        Hold! -key backdrop Wish to draw a quad onto $display with \
            p0 [list 0 0] p1 [list $displayWidth 0] \
            p2 [list $displayWidth $displayHeight] p3 [list 0 $displayHeight] \
            color white layer 99
    }

    # TODO: are we stable?

    # Later: do we see projected tags? record all data

    # we want new camera and projector intrinsics + extrinsics that minimize ....

    # given printed tags, the new extrinsics+intrinsics let you generate projector coordinates which you can match against the board-homography-expected projector coordinates.
    # how do we know the board-homography-expected projector coordinates?
    # well, what are the projector-space coordinates of the printed tags?

    # printed tags in camera space (camera xy) -> pose estimate (camera xyz) -> transform (projector xyz) -> project (projector xy) -> homogrpahy shift to projected tags (projector xy)

    # use projected and printed tags to compute homography. this does not depend on calibration
    # printed tags in camera space (camera xy) -> homography -> printed tags in projector space (projector xy)

    # Later later: Feed to LM along with original calib data
}

}
