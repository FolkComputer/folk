# interactively-refine.folk --
#
#     Implements table-oriented projector-camera end-to-end
#     calibration step.
#

When the pose library is /poseLib/ {

set cc [C]
$cc extend $poseLib

$cc cflags -I./vendor/apriltag
$cc endcflags ./vendor/apriltag/build/libapriltag.so

$cc include <apriltag_pose.h>
$cc include <common/homography.h>
$cc include <common/matd.h>

# From https://courses.cs.duke.edu/cps274/fall13/notes/rodrigues.pdf:
fn rotationMatrixToRotationVector {R} {
    set A [scale 0.5 [sub $R [transpose $R]]]
    set rho [list [getelem $A 2 1] \
                 [getelem $A 0 2] \
                 [getelem $A 1 0]]
    set s [norm $rho]
    set c [expr {([getelem $R 0 0] + [getelem $R 1 1] + [getelem $R 2 2] - 1) / 2}]

    # If s = 0 and c = 1:
    if {abs($s) < 0.0001 && abs($c - 1) < 0.0001} {
        return {0 0 0}
    }
    # If s = 0 and c = -1:
    if {abs($s) < 0.0001 && abs($c - (-1)) < 0.0001} {
        # let v = a nonzero column of R + I
        set v [getcol [add $R [mkIdentity 3]] 0]
        set u [scale [/ 1.0 [norm $v]] $v]
        set r [scale 3.14159 $u]
        if {abs([norm $r] - 3.14159) < 0.0001 &&
            ((abs([getelem $r 0]) < 0.0001 &&
              abs([getelem $r 1]) < 0.0001 &&
              [getelem $r 2] < 0) ||
             (abs([getelem $r 0]) < 0.0001 &&
              [getelem $r 1] < 0) ||
             ([getelem $r 0] < 0))} {
            return [scale -1 $r]
        } else {
            return $r
        }
    }

    set u [scale [/ 1.0 $s] $rho]
    set theta $(atan2($s, $c))
    return [scale $theta $u]
}

fn rotationVectorToRotationMatrix {r} {
    set theta [norm $r]
    if {abs($theta) < 0.0001} {
        return [mkIdentity 3]
    }
    set u [scale [/ 1.0 $theta] $r]
    set ux [list [list 0                       [* -1.0 [getelem $u 2]] [getelem $u 1]] \
                 [list [getelem $u 2]          0                       [* -1.0 [getelem $u 0]]] \
                 [list [* -1.0 [getelem $u 1]] [getelem $u 0]          0]]
    return [add [scale $(cos($theta)) [mkIdentity 3]] \
                [add [scale [expr {1.0 - cos($theta)}] \
                          [matmul $u [transpose $u]]] \
                     [scale $(sin($theta)) $ux]]]
}

# Used to generate the initial guess in estimateBoardPose. Kind of
# misuses the AprilTag pose estimation code to do an entire-board
# estimate (which includes multiple tags).
$cc proc baseEstimateBoardPose {Intrinsics cameraIntrinsics
                                double cameraWidth double cameraHeight
                                double[][2] modelTagCorners double[][2] detectedTagCorners
                                int cornersCount} TagPose {
    // We'll fill this in with a .H that represents all the corners.
    apriltag_detection_t det;

    // The normal tag .H homography goes from (+/-1, +/-1) to the
    // camera-detected tag corners.  We will instead create a
    // board-wide homography from board meters position to the
    // camera-detected tag corners.
    float correspondences[cornersCount][4];
    for (int i = 0; i < cornersCount; i++) {
        correspondences[i][0] = modelTagCorners[i][0];
        correspondences[i][1] = modelTagCorners[i][1];

        double undistortedDetectedTagCorners[2];
        rescaleAndUndistort(cameraIntrinsics, cameraWidth, cameraHeight,
                            detectedTagCorners[i],
                            undistortedDetectedTagCorners);
        correspondences[i][2] = undistortedDetectedTagCorners[0];
        correspondences[i][3] = undistortedDetectedTagCorners[1];
    }
    zarray_t correspondencesArr = {
        .el_sz = sizeof(float[4]), .size = cornersCount, .alloc = cornersCount,
        .data = (char*) correspondences
    };
    det.H = homography_compute(&correspondencesArr,
                               HOMOGRAPHY_COMPUTE_FLAG_SVD);
    apriltag_detection_info_t info = {
        .det = &det,
        .tagsize = 2.0, // scale factor = 1.0
        .fx = cameraIntrinsics.fx, .fy = cameraIntrinsics.fy,
        .cx = cameraIntrinsics.cx, .cy = cameraIntrinsics.cy
    };
    apriltag_pose_t pose;
    estimate_pose_for_tag_homography(&info, &pose);

    matd_destroy(det.H);

    TagPose ret;
    memcpy(ret.R, pose.R->data, sizeof(ret.R));
    memcpy(ret.t, pose.t->data, sizeof(ret.t));

    matd_destroy(pose.R);
    matd_destroy(pose.t);
    return ret;
}
$cc proc estimateBoardPose {Intrinsics cameraIntrinsics
                            double cameraWidth double cameraHeight
                            double[][2] modelTagCorners double[][2] detectedTagCorners
                            int cornersCount} TagPose {
    TagPose baseBoardPose =
        baseEstimateBoardPose(cameraIntrinsics, cameraWidth, cameraHeight,
                              modelTagCorners, detectedTagCorners, cornersCount);

    double wX[cornersCount][3];
    double x[cornersCount][2];
    for (int i = 0; i < cornersCount; i++) {
        rescaleAndUndistort(cameraIntrinsics, cameraWidth, cameraHeight,
                            detectedTagCorners[i],
                            x[i]);
        // Apply intrinsics to go from pixel coordinates to normalized
        // image-plane coordinates:
        x[i][0] = (x[i][0] - cameraIntrinsics.cx) / cameraIntrinsics.fx;
        x[i][1] = (x[i][1] - cameraIntrinsics.cy) / cameraIntrinsics.fy;

        wX[i][0] = modelTagCorners[i][0];
        wX[i][1] = modelTagCorners[i][1];
        wX[i][2] = 0;
    }

    matd_t* cRw = matd_create_data(3, 3, (double*) baseBoardPose.R);
    matd_t* ctw = matd_create_data(3, 1, (double*) baseBoardPose.t);

    poseGaussNewton(wX, x, cornersCount, &cRw, &ctw);

    TagPose ret;
    memcpy(ret.R, cRw->data, sizeof(ret.R));
    memcpy(ret.t, ctw->data, sizeof(ret.t));

    matd_destroy(cRw);
    matd_destroy(ctw);
    return ret;
}

$cc cflags -I./vendor/cmpfit
$cc include "mpfit.h"
$cc include "mpfit.c"
$cc proc funct {int m int n double* x
                double* fvec double** dvec
                void* userdata} int {
    Jim_Obj* jimFunct = (Jim_Obj*) userdata;

    // Build xList from x[0..n-1].
    Jim_Obj* xList = Jim_NewListObj(interp, NULL, 0);
    for (int i = 0; i < n; i++) {
        Jim_ListAppendElement(interp, xList, Jim_NewDoubleObj(interp, x[i]));
    }

    // Expand jimFunct (already an arg list) and append xList, then eval.
    int prefixLen = Jim_ListLength(interp, jimFunct);
    Jim_Obj* objv[prefixLen + 1];
    for (int i = 0; i < prefixLen; i++) {
        __ENSURE_OK(Jim_ListIndex(interp, jimFunct, i, &objv[i], JIM_NONE));
    }
    objv[prefixLen] = xList;
    __ENSURE_OK(Jim_EvalObjVector(interp, prefixLen + 1, objv));

    // Unpack result list into fvec[0..m-1].
    Jim_Obj* result = Jim_GetResult(interp);
    FOLK_ENSURE(Jim_ListLength(interp, result) == m);
    for (int i = 0; i < m; i++) {
        Jim_Obj* elem;
        __ENSURE_OK(Jim_ListIndex(interp, result, i, &elem, JIM_NONE));
        __ENSURE_OK(Jim_GetDouble(interp, elem, &fvec[i]));
    }
    return 0;
}
$cc proc fit {int m int n double[] x Jim_Obj* jimFunct} Jim_Obj* {
    mp_result result = {0};
    mpfit(funct,
          m, // Number of residuals.
          n, x, // Parameters to optimize.
          NULL, NULL, (void*) jimFunct, &result);

    Jim_Obj* xList = Jim_NewListObj(interp, NULL, 0);
    for (int i = 0; i < n; i++) {
        Jim_ListAppendElement(interp, xList, Jim_NewDoubleObj(interp, x[i]));
    }
    return xList;
}

set boardLib [$cc compile]

When the AprilTag detector maker is /makeAprilTagDetector/ &\
     the calibration model library is /modelLib/ &\
     the calibration estimateHomography is /estimateHomography/ &\
     the calibration matLib is /matLib/ &\
     the printed calibration tag size is /printedSideLengthMm/ mm &\
     camera /camera/ has width /cameraWidth/ height /cameraHeight/ &\
     display /display/ has width /displayWidth/ height /displayHeight/ &\
     /someone/ wishes to do interactive refinement {

    fn makeAprilTagDetector
    fn estimateHomography
    set tagDetector [makeAprilTagDetector "tagStandard52h13" 2.0 3]

    package require linalg
    namespace import ::math::linearalgebra::scale \
        ::math::linearalgebra::sub ::math::linearalgebra::add \
        ::math::linearalgebra::transpose ::math::linearalgebra::getelem \
        ::math::linearalgebra::norm ::math::linearalgebra::getcol \
        ::math::linearalgebra::mkIdentity ::math::linearalgebra::matmul

    set printedSideLengthM [/ $printedSideLengthMm 1000.0]
    set model0 [$modelLib scaleModel [$modelLib unitModel] \
                    $printedSideLengthM]

    When /someone/ wishes to draw refining model /model/ using calibration /calibration/ {
        package require linalg
        namespace import ::math::linearalgebra::matmul

        set modelPrintedTagCorners [list]
        set detectedPrintedTagCorners [list]
        foreach tag $tags {
            set id [dict get $tag id]
            if {![$modelLib isPrintedTag $id]} { continue }

            lappend modelPrintedTagCorners {*}[dict get $model $id p]
            lappend detectedPrintedTagCorners {*}[dict get $tag p]
        }
        if {[llength $detectedPrintedTagCorners] < 4} { return }

        # Do a single board-wide pose estimate.
        set pose [$boardLib estimateBoardPose $cameraIntrinsics \
                      $cameraWidth $cameraHeight \
                      $modelPrintedTagCorners $detectedPrintedTagCorners \
                      [llength $detectedPrintedTagCorners]]
        set R_boardToCamera [dict get $pose R]
        set t_boardToCamera [dict get $pose t]

        set R_cameraToDisplay [dict get $calibration R_cameraToProjector]
        set t_cameraToDisplay [dict get $calibration t_cameraToProjector]

        # Compute model-to-display homography from pose via correspondences
        # of the detected printed tag corners:
        set correspondences [lmap mc $modelPrintedTagCorners {
            set v [list {*}$mc 0]
            set camPt [add [matmul $R_boardToCamera $v] $t_boardToCamera]
            set dispPt [add [matmul $R_cameraToDisplay $camPt] $t_cameraToDisplay]
            set dp [$poseLib project $displayIntrinsics \
                        $displayWidth $displayHeight $dispPt]
            list {*}$mc {*}$dp
        }]
        set H_modelToDisplay [estimateHomography $correspondences]

        Wish to draw calibration model $model \
            using model-to-display homography $H_modelToDisplay
    }

    fn AwaitNextCameraFrame! {frameTimestampVar} {
        upvar $frameTimestampVar frameTimestamp
        set prevFrameTimestamp $frameTimestamp
        while {$frameTimestamp <= $prevFrameTimestamp} {
            after 8

            set frames [Query! camera $camera has frame /frame/ at timestamp /frameTimestamp/]
            if {[llength $frames] < 1} { continue }
            set frameResult [lindex $frames end]
            dict with frameResult {}
        }
        return $frame
    }



    # Calibration -> flat list of parameters `x`.
    fn unravel {calibration} {
        set intrNames {fx cx fy cy k1 k2}
        set x [list]
        # Append the camera intrinsics.
        foreach intrName $intrNames {
            lappend x [dict get $calibration camera intrinsics $intrName]
        }
        # Append the projector intrinsics.
        foreach intrName $intrNames {
            lappend x [dict get $calibration projector intrinsics $intrName]
        }
        # Append the camera->projector extrinsics.
        lappend x {*}[rotationMatrixToRotationVector \
            [dict get $calibration R_cameraToProjector]]
        lappend x {*}[dict get $calibration t_cameraToProjector]
    }
    # Flat list of parameters `x` -> update calibration.
    fn ravelInto {calibrationVar x} {
        upvar $calibrationVar calibration
        set intrNames {fx cx fy cy k1 k2}
        set i 0
        foreach intrName $intrNames {
            dict set calibration camera intrinsics $intrName [lindex $x $i]
            incr i
        }
        foreach intrName $intrNames {
            dict set calibration projector intrinsics $intrName [lindex $x $i]
            incr i
        }
        dict set calibration R_cameraToProjector \
            [rotationVectorToRotationMatrix [lrange $x $i $i+2]]
        incr i 3
        dict set calibration t_cameraToProjector [lrange $x $i $i+2]
    }

    set calibration [dict get [QueryOne! the calibration is /calibration/] calibration]
    # The actual refinement process. We will have the user hold up the
    # board in a sequence of whatever poses they want. When the board
    # is stable for a couple seconds, we say that's a pose, and we
    # start refinement with respect to that pose.
    #
    # Once the calibration is refined with respect to the pose, the
    # user can move the board to a different pose. They can stop
    # whenever they want.
    set poses [list]
    set frameTimestamp 0
    while true {
        set frame [AwaitNextCameraFrame! frameTimestamp]
        set aprilTime [time {
            set tags [$tagDetector detect $frame]
        }]

        # Record all the printed tags seen by the camera in $tags.
        
        # TODO: Do we have a valid new pose: are the seen $tags far
        # enough from previous pose's $tags, and have the $tags been
        # stable for a while?

        # Collect correspondences: detected model corners -> camera
        # corners for all printed tags seen this frame.
        set printedCorrespondences [list]
        foreach tag $tags {
            set id [dict get $tag id]
            if {![$modelLib isPrintedTag $id]} { continue }
            foreach modelCorner [dict get $model0 $id p] \
                    camCorner [dict get $tag p] {
                lappend printedCorrespondences \
                    [list {*}$modelCorner {*}$camCorner]
            }
        }
        if {[llength $printedCorrespondences] < 4} { continue }

        # H_mc: model xy -> camera xy.
        set H_mc [estimateHomography $printedCorrespondences]

        # Ideal camera positions for each projected tag corner.
        set idealCameraCorners [list]
        dict for {id modelTag} $model0 {
            if {![$modelLib isProjectedTag $id]} { continue }
            foreach modelCorner [dict get $modelTag p] {
                lappend idealCameraCorners \
                    [$matLib applyHomography $H_mc $modelCorner]
            }
        }

        # 2 residuals (dx, dy) per projected tag corner.
        set m [expr {[llength $idealCameraCorners] * 2}]

        # If so, then refine the parameters around this pose. This
        # will block for a while and run the interior function a lot
        # (10 times? 100 times?).
        set version 0
        set x [unravel $calibration]
        set x [$boardLib fit $m [llength $x] $x [list apply {x} {
            upvar calibration calibration
            upvar version version
            # This block gets run on each iteration of the
            # Levenberg-Marquardt optimization loop.

            ravelInto calibration $x
            set model [$modelLib updateModelVersion $model $version]
            # This will cause the tags to be rendered by the other
            # process.
            Hold! Wish to draw refining model $model using calibration $calibration

            # Loop until we see the version we just wished to draw.
            set expectedVersion [expr {$version % 4}]
            do {
                AwaitNextCameraFrame! frameTimestamp
                set tags [$tagDetector detect $frame]

                set detectedVersion [$modelLib detectVersionFromDetectedTags $tags]
            } while {$detectedVersion != $expectedVersion}

            # TODO: Need to check that the user has kept the board 'still
            # enough' to the original `frame` that kicked off this
            # pose refinement. If not, then abort.

            # FIXME: Compute residuals for each projected tag. (how
            # far away is the tag from where we'd expect it to be from
            # the homography?) Return that list of residuals.

            # If we have barely-not-enough detected projected tags, then
            # fill in some using homography from the ones we did
            # detect. If we have none, we should backtrack.
        }]]
        ravelInto calibration $x
    }
}

}
