# table-refine.folk --
#
#     Implements table-oriented projector-camera end-to-end
#     calibration step.
#

When the tags-to-quads C library is /quadCc/ {

set cc [c create]

$cc struct Intrinsics {
    double width;
    double height;

    double fx;
    double fy;
    double cx;
    double cy;
    double s;

    double k1;
    double k2;
}
$cc import quadCc rescaleAndUndistort as rescaleAndUndistort

$cc cflags -I$::env(HOME)/apriltag $::env(HOME)/apriltag/libapriltag.a
$cc include <apriltag_pose.h>
$cc include <common/homography.h>
$cc include <common/matd.h>

$cc import quadCc poseGaussNewton as poseGaussNewton

# TagPose represents a rotation and translation from tag-space (where
# (0, 0, 0) is the center of the tag) to camera-space (where (0, 0, 0)
# is the center of the camera lens).
$cc struct TagPose {
    double R[3][3];
    double t[3][1];
}

# Used to generate the initial guess in estimateBoardPose. Kind of
# misuses the AprilTag pose estimation code to do an entire-board
# estimate (which includes multiple tags).
$cc proc baseEstimateBoardPose {Intrinsics cameraIntrinsics
                                double cameraWidth double cameraHeight
                                double[][2] modelTagCorners double[][2] detectedTagCorners
                                int cornersCount} TagPose {
    // We'll fill this in with a .H that represents all the corners.
    apriltag_detection_t det;

    // The normal tag .H homography goes from (+/-1, +/-1) to the
    // camera-detected tag corners.  We will instead create a
    // board-wide homography from board meters position to the
    // camera-detected tag corners.
    float correspondences[cornersCount][4];
    for (int i = 0; i < cornersCount; i++) {
        correspondences[i][0] = modelTagCorners[i][0];
        correspondences[i][1] = modelTagCorners[i][1];

        double undistortedDetectedTagCorners[2];
        rescaleAndUndistort(cameraIntrinsics, cameraWidth, cameraHeight,
                            detectedTagCorners[i],
                            undistortedDetectedTagCorners);
        correspondences[i][2] = undistortedDetectedTagCorners[0];
        correspondences[i][3] = undistortedDetectedTagCorners[1];
    }
    zarray_t correspondencesArr = {
        .el_sz = sizeof(float[4]), .size = cornersCount, .alloc = cornersCount,
        .data = (char*) correspondences
    };
    det.H = homography_compute(&correspondencesArr,
                               HOMOGRAPHY_COMPUTE_FLAG_SVD);
    apriltag_detection_info_t info = {
        .det = &det,
        .tagsize = 2.0, // scale factor = 1.0
        .fx = cameraIntrinsics.fx, .fy = cameraIntrinsics.fy,
        .cx = cameraIntrinsics.cx, .cy = cameraIntrinsics.cy
    };
    apriltag_pose_t pose;
    estimate_pose_for_tag_homography(&info, &pose);

    matd_destroy(det.H);

    TagPose ret;
    memcpy(ret.R, pose.R->data, sizeof(ret.R));
    memcpy(ret.t, pose.t->data, sizeof(ret.t));

    matd_destroy(pose.R);
    matd_destroy(pose.t);
    return ret;
}
$cc proc estimateBoardPose {Intrinsics cameraIntrinsics
                            double cameraWidth double cameraHeight
                            double[][2] modelTagCorners double[][2] detectedTagCorners
                            int cornersCount} TagPose {
    double wX[cornersCount][3];
    double x[cornersCount][2];
    for (int i = 0; i < cornersCount; i++) {
        rescaleAndUndistort(cameraIntrinsics, cameraWidth, cameraHeight,
                            detectedTagCorners[i],
                            x[i]);
        // Apply intrinsics to go from pixel coordinates to normalized
        // image-plane coordinates:
        x[i][0] = (x[i][0] - cameraIntrinsics.cx) / cameraIntrinsics.fx;
        x[i][1] = (x[i][1] - cameraIntrinsics.cy) / cameraIntrinsics.fy;

        wX[i][0] = modelTagCorners[i][0];
        wX[i][1] = modelTagCorners[i][1];
        wX[i][2] = 0;
    }

    TagPose baseBoardPose =
        baseEstimateBoardPose(cameraIntrinsics, cameraWidth, cameraHeight,
                              modelTagCorners, detectedTagCorners,
                              cornersCount);
    matd_t* cRw = matd_create_data(3, 3, (double*) baseBoardPose.R);
    matd_t* ctw = matd_create_data(3, 1, (double*) baseBoardPose.t);

    poseGaussNewton(wX, x, 4, &cRw, &ctw);

    TagPose ret;
    memcpy(ret.R, cRw->data, sizeof(ret.R));
    memcpy(ret.t, ctw->data, sizeof(ret.t));

    matd_destroy(cRw);
    matd_destroy(ctw);
    return ret;
}
$cc compile

}

When the calibration isPrintedTag is /isPrintedTag/ &\
     the printed calibration tag size is /printedSideLengthMm/ mm &\
     camera /camera/ has intrinsics /cameraIntrinsics/ &\
     camera /camera/ has width /cameraWidth/ height /cameraHeight/ &\
     /someone/ wishes to do table refinement {
    
    When main-detector detects tags /tags/ on $camera at /timestamp/ in time /something/ {
        set printedTags [list]
        foreach tag $tags {
            set id [dict get $tag id]
            if {[{*}$isPrintedTag $id]} { lappend printedTags $tag }
        }

        # Do a single board-wide pose estimate.
        estimateBoardPose $cameraIntrinsics $cameraWidth $cameraHeight \
            [/ $printedSideLengthMm 1000.0] \
            $modelPrintedTagCorners $detectedPrintedTagCorners
        # Project a bunch of tags based on the pose estimate.

    }

    # TODO: are we stable?

    # Later: do we see projected tags? record all data

    # we want new camera and projector intrinsics + extrinsics that minimize ....

    # given printed tags, the new extrinsics+intrinsics let you generate projector coordinates which you can match against the board-homography-expected projector coordinates.
    # how do we know the board-homography-expected projector coordinates?
    # well, what are the projector-space coordinates of the printed tags?

    # printed tags in camera space (camera xy) -> pose estimate (camera xyz) -> transform (projector xyz) -> project (projector xy) -> homogrpahy shift to projected tags (projector xy)

    # use projected and printed tags to compute homography. this does not depend on calibration
    # printed tags in camera space (camera xy) -> homography -> printed tags in projector space (projector xy)

    # Later later: Feed to LM along with original calib data
}
