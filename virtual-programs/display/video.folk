On process "display" {
    # Minimal video state management
    namespace eval VideoState {
        variable sources; array set sources {}
        variable metadata; array set metadata {}
        variable debug 1
        
        proc log {level message} {
            variable debug
            if {$level <= 1 || $debug} {
                puts "\[VIDEO:[lindex {ERROR WARN INFO} $level]\] $message"
            }
        }
        
        proc registerSource {thing source} {
            variable sources
            set sources($thing) $source
            log 2 "Registered source $source for $thing"
        }
        
        proc getSource {thing} {
            variable sources
            if {[info exists sources($thing)]} {return $sources($thing)}
            return ""
        }
        
        proc updateMetadata {source fps duration frames} {
            variable metadata
            if {![info exists metadata($source)]} {set metadata($source) [dict create]}
            dict set metadata($source) fps $fps
            dict set metadata($source) duration $duration
            dict set metadata($source) totalFrames $frames
            log 2 "Updated metadata for $source: fps=$fps duration=$duration frames=$frames"
        }
        
        proc getMetadata {source} {
            variable metadata
            if {[info exists metadata($source)]} {return $metadata($source)}
            return [dict create fps 30.0 duration 1.0 totalFrames 30]
        }
        
        proc setStartTime {thing time} {
            variable metadata
            if {![info exists metadata($thing)]} {set metadata($thing) [dict create]}
            dict set metadata($thing) startTime $time
            log 2 "Set start time for $thing to $time"
        }
        
        proc getStartTime {thing {default 0}} {
            variable metadata
            if {[info exists metadata($thing)] && [dict exists $metadata($thing) startTime]} {
                return [dict get $metadata($thing) startTime]
            }
            return $default
        }
        
        proc getFrameNumber {thing time} {
            set startTime [getStartTime $thing]
            if {$startTime == 0} {return 1}
            
            set relativeTime [expr {$time - $startTime}]
            if {$relativeTime < 0} {return 1}
            
            set source [getSource $thing]
            if {$source eq ""} {return 1}
            
            set sourceInfo [getMetadata $source]
            set fps [dict get $sourceInfo fps]
            set totalFrames [dict get $sourceInfo totalFrames]
            set duration [dict get $sourceInfo duration]
            
            # Proper looping - use modulo on time
            if {$duration > 0} {set relativeTime [expr {fmod($relativeTime, $duration)}]}
            
            set frameNum [expr {int($relativeTime * $fps) + 1}]
            if {$frameNum > $totalFrames && $totalFrames > 0} {set frameNum $totalFrames}
            
            return $frameNum
        }
    }

    namespace eval video {
        set cc [c create]
        ::defineImageType $cc
        $cc cflags -lavcodec -lavformat -lavutil -lswscale -Wno-deprecated-declarations

        # Load libraries
        if {$tcl_platform(os) eq "Darwin"} {
            c loadlib "/opt/homebrew/lib/libavutil.dylib"
            c loadlib "/opt/homebrew/lib/libavcodec.dylib"
            c loadlib "/opt/homebrew/lib/libavformat.dylib"
            c loadlib "/opt/homebrew/lib/swscale.dylib"
        } else {
            catch {
                c loadlib "/usr/lib/x86_64-linux-gnu/libavutil.so"
                c loadlib "/usr/lib/x86_64-linux-gnu/libavcodec.so"
                c loadlib "/usr/lib/x86_64-linux-gnu/libavformat.so"
                c loadlib "/usr/lib/x86_64-linux-gnu/libswscale.so"
            }
        }
        
        $cc include <stdio.h>
        $cc include <stdlib.h>
        $cc include <string.h>
        $cc include <libavutil/imgutils.h>
        $cc include <libavcodec/avcodec.h>
        $cc include <libavformat/avformat.h>
        $cc include <libswscale/swscale.h>

        $cc import ::Heap::cc folkHeapAlloc as folkHeapAlloc
        $cc import ::Heap::cc folkHeapFree as folkHeapFree

        $cc proc init {} void {}

        # Debug image
        $cc proc generateDebugImage {} image_t {
            image_t ret;
            ret.width = 120;
            ret.height = 90;
            ret.components = 4;
            ret.bytesPerRow = ret.width * ret.components;
            ret.data = folkHeapAlloc(ret.bytesPerRow * ret.height);
            
            if (ret.data) {
                // Fill with magenta for debugging
                for (int y = 0; y < ret.height; y++) {
                    for (int x = 0; x < ret.width; x++) {
                        int offset = y * ret.bytesPerRow + x * ret.components;
                        ret.data[offset] = 255;     // R
                        ret.data[offset + 1] = 0;   // G
                        ret.data[offset + 2] = 255; // B
                        ret.data[offset + 3] = 255; // A
                    }
                }
            }
            return ret;
        }
        
        # Forward declaration for cache functions
        $cc code {
            // Cache functions forward declarations
            void videoFreeCacheResources(void);
            int videoGetCachedFrame(const char* path, int frameNum, image_t* outImage);
            void videoCacheFrame(const char* path, int frameNum, image_t image);
            int isDebugFrame(image_t image);
        }
        
        # Cache implementation
        $cc code {
            // Simple frame cache - fixed to 3 entries
            typedef struct {
                image_t frame;
                int frameNumber;
                char path[256];
                int lastUsed;
                int isValid;
            } CacheEntry;
            
            CacheEntry frameCache[3];
            int cacheTimestamp = 0;
            int initialized = 0;
            
            // Check if frame is a debug frame
            int isDebugFrame(image_t image) {
                if (!image.data || image.width < 10) return 1;
                
                // Check center pixel for magenta
                int x = image.width / 2;
                int y = image.height / 2;
                int offset = y * image.bytesPerRow + x * image.components;
                
                return (image.data[offset] > 200 && 
                        image.data[offset+1] < 50 && 
                        image.data[offset+2] > 200);
            }
            
            // Find oldest cache entry
            int findOldestEntry() {
                int oldest = 0;
                for (int i = 1; i < 3; i++) {
                    if (!frameCache[i].isValid || 
                        frameCache[i].lastUsed < frameCache[oldest].lastUsed) {
                        oldest = i;
                    }
                }
                return oldest;
            }
            
            // Initialize cache
            void initCache() {
                if (initialized) return;
                
                for (int i = 0; i < 3; i++) {
                    frameCache[i].frame.data = NULL;
                    frameCache[i].isValid = 0;
                }
                initialized = 1;
            }
            
            // Free cache resources
            void videoFreeCacheResources() {
                for (int i = 0; i < 3; i++) {
                    if (frameCache[i].frame.data) {
                        folkHeapFree(frameCache[i].frame.data);
                        frameCache[i].frame.data = NULL;
                        frameCache[i].isValid = 0;
                    }
                }
            }
            
            // Get cached frame
            int videoGetCachedFrame(const char* path, int frameNum, image_t* outImage) {
                initCache();
                
                for (int i = 0; i < 3; i++) {
                    if (frameCache[i].isValid && 
                        frameCache[i].frameNumber == frameNum &&
                        strcmp(frameCache[i].path, path) == 0) {
                        
                        frameCache[i].lastUsed = ++cacheTimestamp;
                        *outImage = frameCache[i].frame;
                        return 1;
                    }
                }
                return 0;
            }
            
            // Store frame in cache
            void videoCacheFrame(const char* path, int frameNum, image_t image) {
                initCache();
                
                // Don't cache debug frames
                if (isDebugFrame(image)) return;
                
                // Find existing entry or oldest one
                int idx = -1;
                for (int i = 0; i < 3; i++) {
                    if (frameCache[i].isValid && 
                        frameCache[i].frameNumber == frameNum &&
                        strcmp(frameCache[i].path, path) == 0) {
                        idx = i;
                        break;
                    }
                }
                
                if (idx < 0) {
                    idx = findOldestEntry();
                    
                    // Free old frame if present
                    if (frameCache[idx].frame.data) {
                        folkHeapFree(frameCache[idx].frame.data);
                    }
                }
                
                // Update cache entry
                strncpy(frameCache[idx].path, path, 255);
                frameCache[idx].frameNumber = frameNum;
                frameCache[idx].frame = image;
                frameCache[idx].lastUsed = ++cacheTimestamp;
                frameCache[idx].isValid = 1;
            }
        }
        
        # Video metadata analysis
        $cc proc analyzeVideo {Tcl_Interp* interp char* videoPath} void {
            char updCmd[256];
            double fps = 30.0;
            double duration = 1.0;
            int total_frames = 30;
            
            AVFormatContext *pFormatContext = avformat_alloc_context();
            if (pFormatContext && 
                avformat_open_input(&pFormatContext, videoPath, NULL, NULL) == 0 && 
                avformat_find_stream_info(pFormatContext, NULL) >= 0) {
                
                // Find video stream
                int video_stream_index = -1;
                for (int i = 0; i < pFormatContext->nb_streams; i++) {
                    if (pFormatContext->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
                        video_stream_index = i;
                        break;
                    }
                }
                
                if (video_stream_index >= 0) {
                    // Get video info
                    fps = av_q2d(pFormatContext->streams[video_stream_index]->avg_frame_rate);
                    duration = pFormatContext->duration / (double)AV_TIME_BASE;
                    total_frames = pFormatContext->streams[video_stream_index]->nb_frames;
                    
                    // Estimate frame count if not available
                    if (total_frames <= 0) {
                        total_frames = (int)(duration * fps);
                    }
                    
                    // Fallback for invalid values
                    if (fps <= 0) fps = 30.0;
                    if (duration <= 0) duration = 1.0;
                    if (total_frames <= 0) total_frames = 30;
                }
                
                avformat_close_input(&pFormatContext);
            }
            
            // Update metadata
            snprintf(updCmd, sizeof(updCmd), 
                    "VideoState::updateMetadata {%s} %.2f %.2f %d",
                    videoPath, fps, duration, total_frames);
            Tcl_Eval(interp, updCmd);
        }
        
        # Simplified frame fetcher
        $cc proc getVideoFrame {Tcl_Interp* interp char* videoPath int targetFrame} image_t {
            // Check cache first
            image_t cachedImage;
            if (videoGetCachedFrame(videoPath, targetFrame, &cachedImage)) {
                if (!isDebugFrame(cachedImage)) {
                    return cachedImage;
                }
            }
            
            // Default error image
            image_t errorImage = generateDebugImage();
            
            AVFormatContext *pFormatContext = NULL;
            AVCodecContext *pCodecContext = NULL;
            AVPacket *pPacket = NULL;
            AVFrame *pFrame = NULL;
            AVFrame *pFrameRGB = NULL;
            struct SwsContext *sws_ctx = NULL;
            uint8_t *buffer = NULL;
            int video_stream_index = -1;
            image_t result = {0};
            
            // Basic FFmpeg setup
            if (!(pFormatContext = avformat_alloc_context()) ||
                avformat_open_input(&pFormatContext, videoPath, NULL, NULL) != 0 ||
                avformat_find_stream_info(pFormatContext, NULL) < 0) {
                goto cleanup;
            }
            
            // Find video stream
            for (int i = 0; i < pFormatContext->nb_streams; i++) {
                if (pFormatContext->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
                    video_stream_index = i;
                    break;
                }
            }
            
            if (video_stream_index == -1) goto cleanup;
            
            // Set up codec
            const AVCodec *pCodec = avcodec_find_decoder(
                pFormatContext->streams[video_stream_index]->codecpar->codec_id);
                
            if (!pCodec ||
                !(pCodecContext = avcodec_alloc_context3(pCodec)) ||
                avcodec_parameters_to_context(pCodecContext, 
                    pFormatContext->streams[video_stream_index]->codecpar) < 0 ||
                avcodec_open2(pCodecContext, pCodec, NULL) < 0) {
                goto cleanup;
            }
            
            // Allocate packet and frames
            if (!(pPacket = av_packet_alloc()) || 
                !(pFrame = av_frame_alloc()) || 
                !(pFrameRGB = av_frame_alloc())) {
                goto cleanup;
            }
            
            // Seek to approximate position
            if (targetFrame > 1) {
                double fps = av_q2d(pFormatContext->streams[video_stream_index]->avg_frame_rate);
                double seekSec = (targetFrame - 1) / fps;
                int64_t seekTimestamp = av_rescale_q(
                    (int64_t)(seekSec * AV_TIME_BASE),
                    AV_TIME_BASE_Q,
                    pFormatContext->streams[video_stream_index]->time_base
                );
                
                av_seek_frame(pFormatContext, video_stream_index, 
                              seekTimestamp, AVSEEK_FLAG_BACKWARD);
                avcodec_flush_buffers(pCodecContext);
            }
            
            // Read and decode frames
            int currentFrame = 0;
            int frameFound = 0;
            
            while (!frameFound && av_read_frame(pFormatContext, pPacket) >= 0 && currentFrame < 200) {
                if (pPacket->stream_index != video_stream_index) {
                    av_packet_unref(pPacket);
                    continue;
                }
                
                if (avcodec_send_packet(pCodecContext, pPacket) < 0) {
                    av_packet_unref(pPacket);
                    continue;
                }
                
                while (!frameFound && avcodec_receive_frame(pCodecContext, pFrame) >= 0) {
                    currentFrame++;
                    
                    if (currentFrame == targetFrame) {
                        frameFound = 1;
                        
                        // Skip invalid frames
                        if (!pFrame->data[0]) {
                            frameFound = 0;
                            break;
                        }
                        
                        // Limit dimensions to save memory
                        int width = pFrame->width;
                        int height = pFrame->height;
                        
                        if (width > 480) width = 480;
                        if (height > 360) height = 360;
                        
                        // Set up RGB conversion
                        pFrameRGB->format = AV_PIX_FMT_RGB24;
                        pFrameRGB->width = width;
                        pFrameRGB->height = height;
                        
                        int bufferSize = av_image_get_buffer_size(AV_PIX_FMT_RGB24, width, height, 1);
                        if (bufferSize <= 0) {
                            frameFound = 0;
                            break;
                        }
                        
                        buffer = (uint8_t*)av_malloc(bufferSize);
                        if (!buffer) {
                            frameFound = 0;
                            break;
                        }
                        
                        av_image_fill_arrays(pFrameRGB->data, pFrameRGB->linesize, buffer,
                            AV_PIX_FMT_RGB24, width, height, 1);
                        
                        sws_ctx = sws_getContext(
                            pFrame->width, pFrame->height, pCodecContext->pix_fmt,
                            width, height, AV_PIX_FMT_RGB24,
                            SWS_BILINEAR, NULL, NULL, NULL);
                            
                        if (!sws_ctx) {
                            av_free(buffer);
                            frameFound = 0;
                            break;
                        }
                        
                        if (sws_scale(sws_ctx, (const uint8_t* const*)pFrame->data, 
                                     pFrame->linesize, 0, pFrame->height, 
                                     pFrameRGB->data, pFrameRGB->linesize) <= 0) {
                            sws_freeContext(sws_ctx);
                            av_free(buffer);
                            frameFound = 0;
                            break;
                        }
                        
                        // Create Folk image
                        result.width = width;
                        result.height = height;
                        result.components = 4;
                        result.bytesPerRow = result.width * result.components;
                        
                        result.data = folkHeapAlloc(result.height * result.bytesPerRow);
                        if (!result.data) {
                            sws_freeContext(sws_ctx);
                            av_free(buffer);
                            frameFound = 0;
                            break;
                        }
                        
                        // Copy RGB -> RGBA
                        for (int y = 0; y < result.height; y++) {
                            uint8_t *dstRow = result.data + (y * result.bytesPerRow);
                            uint8_t *srcRow = pFrameRGB->data[0] + (y * pFrameRGB->linesize[0]);
                            
                            for (int x = 0; x < result.width; x++) {
                                uint8_t *src = srcRow + (x * 3);
                                uint8_t *dst = dstRow + (x * result.components);
                                
                                dst[0] = src[0];     // R
                                dst[1] = src[1];     // G
                                dst[2] = src[2];     // B
                                dst[3] = 255;        // A
                            }
                        }
                        
                        // Cache the frame
                        videoCacheFrame(videoPath, targetFrame, result);
                    }
                }
                
                av_packet_unref(pPacket);
            }
            
            // Return the frame if found
            if (frameFound && result.data) {
                if (buffer) av_free(buffer);
                if (sws_ctx) sws_freeContext(sws_ctx);
                if (pFrameRGB) av_frame_free(&pFrameRGB);
                if (pFrame) av_frame_free(&pFrame);
                if (pPacket) av_packet_free(&pPacket);
                if (pCodecContext) avcodec_free_context(&pCodecContext);
                if (pFormatContext) avformat_close_input(&pFormatContext);
                
                return result;
            }
            
        cleanup:
            if (buffer) av_free(buffer);
            if (sws_ctx) sws_freeContext(sws_ctx);
            if (pFrameRGB) av_frame_free(&pFrameRGB);
            if (pFrame) av_frame_free(&pFrame);
            if (pPacket) av_packet_free(&pPacket);
            if (pCodecContext) avcodec_free_context(&pCodecContext);
            if (pFormatContext) avformat_close_input(&pFormatContext);
            
            return errorImage;
        }
        
        # Clear cache
        $cc proc freeCache {} void {
            videoFreeCacheResources();
        }

        $cc compile
        init

        namespace export *
        namespace ensemble create
    }

    # Register for events
    Wish $::thisProcess receives statements like \
        [list /someone/ wishes /thing/ displays video /videoSrc/]
    Wish $::thisProcess receives statements like \
        [list /someone/ claims /thing/ has region /r/]
    Wish $::thisProcess shares statements like \
        [list /someone/ wishes to draw an image with center /c/ image /im/ radians /radians/]
    Wish $::thisProcess shares statements like \
        [list /someone/ wishes /thing/ is titled /title/]
    Wish $::thisProcess receives statements like \
        [list /someone/ claims the clock time is /t/]

    # Handle video source changes
    When /someone/ wishes /thing/ displays video /videoSrc/ {
        puts stderr "Will play video: $videoSrc"
        VideoState::registerSource $thing $videoSrc
        Claim $thing has videoSource $videoSrc
        Claim $thing has videoStartTime 0
        video::analyzeVideo $videoSrc
    }

    # Video playback processor
    When /someone/ wishes /thing/ displays video /videoSrc/ & /thing/ has region /r/ & the clock time is /t/ {
        # Track state
        variable lastFrame
        variable lastFrameNum
        
        # Get metadata
        set metadata [VideoState::getMetadata $videoSrc]
        set fps [dict get $metadata fps]
        set totalFrames [dict get $metadata totalFrames]
        set duration [dict get $metadata duration]
        
        # Reset if needed
        set startTime [VideoState::getStartTime $thing]
        if {$startTime == 0} {
            VideoState::setStartTime $thing $t
            Claim $thing has videoStartTime $t
            set startTime $t
        }
        
        # Calculate frame with looping
        set frameNum [VideoState::getFrameNumber $thing $t]
        
        # Skip redundant processing
        if {[info exists lastFrameNum($thing)] && $lastFrameNum($thing) == $frameNum} {
            if {[info exists lastFrame($thing)]} {
                set center [region centroid $r]
                set angle [region angle $r]
                Wish to draw an image with center $center image $lastFrame($thing) radians $angle
            }
            return
        }
        
        # Update tracking
        set lastFrameNum($thing) $frameNum
        
        # Get the frame
        if {[catch {
            set frame [video::getVideoFrame $videoSrc $frameNum]
            set lastFrame($thing) $frame
            
            # Display frame
            set center [region centroid $r]
            set angle [region angle $r]
            Wish to draw an image with center $center image $frame radians $angle
            
            # Update title with loop info
            set elapsedTime [expr {$t - $startTime}]
            set loopCount [expr {int($elapsedTime / $duration)}]
            Wish $thing is titled "Video: [file tail $videoSrc] ($frameNum/$totalFrames, Loop: $loopCount)"
        } err]} {
            # Error handling
            VideoState::log 0 "Error: $err"
            
            # Try to use previous frame
            if {[info exists lastFrame($thing)]} {
                set center [region centroid $r]
                set angle [region angle $r]
                Wish to draw an image with center $center image $lastFrame($thing) radians $angle
            }
            
            # Reset if too many errors
            if {[incr errorCount($thing) 0] > 5} {
                VideoState::setStartTime $thing 0
                Claim $thing has videoStartTime 0
                video::freeCache
                set errorCount($thing) 0
            }
        }
    }
}

# Example: Wish $this displays video "/path/to/video.mp4"