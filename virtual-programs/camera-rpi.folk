if {$::isLaptop} return

set makeCamera {
    set cpp [C++]
    $cpp include <iostream>
    $cpp include <iomanip>
    $cpp include <atomic>
    $cpp include <sys/mman.h>

    $cpp include <libcamera/libcamera.h>
    # osnr: HACK: because I'm building libcamera locally for now.
    $cpp cflags -I/usr/local/include/libcamera
    c loadlibLd libcamera

    defineImageType $cpp
    $cpp code {
        using namespace libcamera;

        std::unique_ptr<CameraManager> cm;
        std::shared_ptr<Camera> camera;
	std::unique_ptr<CameraConfiguration> config;
	FrameBufferAllocator *allocator;

        // This vector always owns all the request objects.
	std::vector<std::unique_ptr<Request>> requests;

        std::atomic<Request *> latestRequest;

        uint32_t frameWidth;
        uint32_t frameHeight;
        uint32_t frameBytesPerRow;

        static void requestComplete(Request *request);
    }
    $cpp proc cameraOpen {char* id int width int height} void {
        cm = std::make_unique<CameraManager>();
        cm->start();

        std::cout << "camera-rpi: cameras:" << std::endl;
	for (auto const &camera : cm->cameras()) {
            std::cout << " - " << camera->id() << std::endl;
        }

        camera = cm->get(id);
        camera->acquire();

        config = camera->generateConfiguration({ StreamRole::Viewfinder });
        StreamConfiguration &streamConfig = config->at(0);
        config->validate();
        frameWidth = streamConfig.size.width;
        frameHeight = streamConfig.size.height;
        frameBytesPerRow = streamConfig.stride;

	camera->configure(config.get());

        allocator = new FrameBufferAllocator(camera);
	for (StreamConfiguration &cfg : *config) {
            int ret = allocator->allocate(cfg.stream());
            if (ret < 0) {
                FOLK_ERROR("Can't allocate buffers");
            }

            size_t allocated = allocator->buffers(cfg.stream()).size();
            std::cout << "camera-rpi: Allocated " << allocated << " buffers for stream" << std::endl;
	}

        Stream *stream = streamConfig.stream();
        assert(streamConfig.pixelFormat.toString() == "XRGB8888");

        const std::vector<std::unique_ptr<FrameBuffer>> &buffers = allocator->buffers(stream);
	for (unsigned int i = 0; i < buffers.size(); ++i) {
		std::unique_ptr<Request> request = camera->createRequest();
		if (!request) {
                    FOLK_ERROR("camera-rpi: Can't create request");
		}

		const std::unique_ptr<FrameBuffer> &buffer = buffers[i];
		int ret = request->addBuffer(stream, buffer.get());
		if (ret < 0) {
                    FOLK_ERROR("camera-rpi: Can't set buffer for request");
		}

		/*
		 * Controls can be added to a request on a per frame basis.
		 */
		ControlList &controls = request->controls();
		controls.set(controls::Brightness, 0.5);

		requests.push_back(std::move(request));
	}

	camera->requestCompleted.connect(requestComplete);

        camera->start();
	for (std::unique_ptr<Request> &request : requests) {
            camera->queueRequest(request.get());
        }
    }

    $cpp code {
        static void requestComplete(Request *request) {
            if (request->status() == Request::RequestCancelled) {
		return;
            }

            printf("======== REQUEST COMPLETE========\n");

            Request *prevLatestRequest;
            do {
                prevLatestRequest = latestRequest;
            } while (!latestRequest.compare_exchange_weak(prevLatestRequest, request));

            if (prevLatestRequest != nullptr) {
                // Re-dispatch this request that we're skipping.
                request->reuse(Request::ReuseBuffers);
                camera->queueRequest(request);
            }
        }

        static void imageCopyGray(image_t to, image_t from) {
            FOLK_ENSURE(from.components == 4);
            FOLK_ENSURE(from.width == to.width);
            FOLK_ENSURE(from.height == to.height);

            for (uint32_t y = 0; y < from.height; y++) {
                for (uint32_t x = 0; x < from.width; x++) {
                    uint32_t i = (y * from.bytesPerRow) + x * 4;
                    // FIXME: XRGB8888 assumed
                    uint32_t r = from.data[i + 1];
                    uint32_t g = from.data[i + 2];
                    uint32_t b = from.data[i + 3];
                    // from https://mina86.com/2021/rgb-to-greyscale/
                    uint32_t yy = 3567664 * r + 11998547 * g + 1211005 * b;
                    to.data[y * to.bytesPerRow + x] = ((yy + (1 << 23)) >> 24);
                }
            }
        }

        static void processRequestAndCopyFrame(Request *request, image_t im) {
            // printf("processRequest (%p)\n", request);
            // std::cout << std::endl
            //           << "Request completed: " << request->toString() << std::endl;

            /*
             * When a request has completed, it is populated with a metadata control
             * list that allows an application to determine various properties of
             * the completed request. This can include the timestamp of the Sensor
             * capture, or its gain and exposure values, or properties from the IPA
             * such as the state of the 3A algorithms.
             *
             * ControlValue types have a toString, so to examine each request, print
             * all the metadata for inspection. A custom application can parse each
             * of these items and process them according to its needs.
             */
            // const ControlList &requestMetadata = request->metadata();
            // for (const auto &ctrl : requestMetadata) {
            //         const ControlId *id = controls::controls.at(ctrl.first);
            //         const ControlValue &value = ctrl.second;

            //         // std::cout << "\t" << id->name() << " = " << value.toString()
            //         //           << std::endl;
            // }

            /*
             * Each buffer has its own FrameMetadata to describe its state, or the
             * usage of each buffer. While in our simple capture we only provide one
             * buffer per request, a request can have a buffer for each stream that
             * is established when configuring the camera.
             *
             * This allows a viewfinder and a still image to be processed at the
             * same time, or to allow obtaining the RAW capture buffer from the
             * sensor along with the image as processed by the ISP.
             */
            const Request::BufferMap &buffers = request->buffers();
            assert(buffers.size() == 1);
            for (auto bufferPair : buffers) {
                    // (Unused) Stream *stream = bufferPair.first;
                    FrameBuffer *buffer = bufferPair.second;
                    const FrameMetadata &metadata = buffer->metadata();

                    /* Print some information about the buffer which has completed. */
                    // std::cout << " seq: " << std::setw(6) << std::setfill('0') << metadata.sequence
                    //           << " timestamp: " << metadata.timestamp
                    //           << " bytesused: ";

                    // unsigned int nplane = 0;
                    // for (const FrameMetadata::Plane &plane : metadata.planes())
                    // {
                    //         std::cout << plane.bytesused;
                    //         if (++nplane < metadata.planes().size())
                    //                 std::cout << "/";
                    // }
                    assert(metadata.planes().size() == 1);
                    assert(buffer->planes().size() == 1);
                    
                    auto &plane = buffer->planes()[0];
                    int fd = plane.fd.get();
                    
                    /*
                     * Image data can be accessed here, but the FrameBuffer
                     * must be mapped by the application
                     */
                    void *addr = mmap64(NULL, plane.length, PROT_READ, MAP_PRIVATE, fd, 0);
                    if (addr == MAP_FAILED) {
                        FOLK_ERROR("camera-rpi: MAP_FAILED");
                    }
                    void *planeData = (uint8_t *)addr + plane.offset;
                    image_t planeIm = {
                        .width = frameWidth, .height = frameHeight,
                        .components = 4, .bytesPerRow = frameBytesPerRow,
                        .data = (uint8_t *)planeData
                    };
                    imageCopyGray(im, planeIm);
                    munmap(addr, plane.length);
            }

            /* Re-queue the Request to the camera. */
            request->reuse(Request::ReuseBuffers);
            camera->queueRequest(request);
        }
    }

    $cpp import ::Heap::cc folkHeapAlloc as folkHeapAlloc
    $cpp import ::Heap::cc folkHeapFree as folkHeapFree

    $cpp proc newImage {} image_t {
        uint32_t width = frameWidth;
        uint32_t height = frameHeight;
        int components = 1;
        uint8_t *data = (uint8_t *)folkHeapAlloc(width*components*height);
        return (image_t) {
            .width = width,
            .height = height,
            .components = components,
            .bytesPerRow = width*components,
            .data = data
        };
    }
    $cpp proc freeImage {image_t image} void {
        folkHeapFree(image.data);
    }

    $cpp proc grayFrame {} image_t {
        // We want to take exclusive ownership over the request.
        Request *request;
        do {
            request = latestRequest;
        } while (!latestRequest.compare_exchange_weak(request, nullptr));

        if (request == nullptr) { FOLK_ERROR("No new frame yet"); }

        image_t im = newImage();
        processRequestAndCopyFrame(request, im);
        printf("Got new frame\n");
        return im;
    }

    $cpp compile
}

When /someone/ wishes $::thisNode uses camera /cameraPath/ with /...options/ {
    if {![string match "/base*" $cameraPath]} { return }

    puts "camera-rpi: Running."

    set width [dict get $options width]
    set height [dict get $options height]
    Start process "camera $cameraPath $options" {
        Wish $::thisProcess shares statements like \
            [list /someone/ claims camera $cameraPath /...anything/]

        namespace eval Camera $makeCamera
        Camera::cameraOpen $cameraPath $width $height

        # TODO: report actual width and height from libcamera
        Claim camera $cameraPath has width $width height $height

        puts "camera-rpi: $cameraPath ($options) (tid [getTid]) booted at [clock milliseconds]"

        set ::oldFrames [list]
        When $::thisProcess has step count /c/ {
            try {
                set frame [Camera::grayFrame]
            } on error e { return }

            Hold {
                Claim camera $cameraPath has camera time $::stepTime
                Claim camera $cameraPath has frame $frame at timestamp [expr {[clock milliseconds] / 1000.0}]
            }
            lappend ::oldFrames $frame
            if {[llength $::oldFrames] >= 10} {
                set ::oldFrames [lassign $::oldFrames oldestFrame]
                Camera::freeImage $oldestFrame
            }
        }
    }
}

# TODO: remove this; useful for compatibility with current metrics but
# doesn't work for multicam
set ::cameraTime none
When camera /any/ has camera time /cameraTime/ {
    set ::cameraTime $cameraTime
}
